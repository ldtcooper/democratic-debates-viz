{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "html_string = requests.get('https://www.washingtonpost.com/politics/2019/07/31/transcript-first-night-second-democratic-debate/').content\n",
    "html_tree = BeautifulSoup(html_string, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_html(tag):\n",
    "    # gets all p tags with no i tags in them\n",
    "    if tag.name == 'p' and not tag.i:\n",
    "        if re.match('\\([A-Z ]+\\)', tag.text):\n",
    "            # filters out placeholders like '(APPLAUSE)' and '(LAUGHTER)'\n",
    "            return False\n",
    "        return True\n",
    "    else:\n",
    "        return False \n",
    "    \n",
    "    \n",
    "p_collection = html_tree.find('article').find_all(filter_html)\n",
    "# we don't want to include the moderators in our table\n",
    "\n",
    "moderators = ['TAPPER', 'BASH', 'LEMON']\n",
    "last_match = None\n",
    "word_frequencies = {'TOTAL': {}}\n",
    "for p in p_collection:\n",
    "    if p.string == None:\n",
    "        continue\n",
    "    tag_text = p.string.replace('\\n', '')\n",
    "    tag_matcher = '^(([A-Z]+)( \\(\\?\\))?): (.+)$'; # grabs the name of the speaker\n",
    "    speaker_match = re.match(tag_matcher, tag_text)\n",
    "    # some new p tags continue the last speaker's thought and don't have a name in front\n",
    "    if speaker_match:\n",
    "        # if there is a name in front, we know there is a new speaker\n",
    "        name = speaker_match.group(2)\n",
    "        last_match = name\n",
    "        dialog = speaker_match.group(4)\n",
    "    else:\n",
    "        # otherwise, use the last name we saw\n",
    "        name = last_match\n",
    "        dialog = tag_text\n",
    "    if name in moderators:\n",
    "        # throw out moderator dialog\n",
    "        last_match = name\n",
    "        continue\n",
    "    if name not in word_frequencies:\n",
    "        word_frequencies[name] = {}\n",
    "    # turn all instances of 'health care' into 'healthcare' and count up words\n",
    "    word_list = dialog.replace('health care', 'healthcare').split(' ')\n",
    "    for word in word_list:\n",
    "        word = word.lower()\n",
    "        word = re.sub('[.,\\?!\"\\d\\$-]+', '', word)\n",
    "        if word == '':\n",
    "            continue\n",
    "        if word in word_frequencies[name]:\n",
    "            word_frequencies[name][word] += 1\n",
    "            word_frequencies['TOTAL'][word] += 1\n",
    "        else:\n",
    "            word_frequencies[name][word] = 1\n",
    "            word_frequencies['TOTAL'][word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell, we are parsing through the HTML of the debate page from the Washington Post to extract all `<p>` tags in the `<article>` tag. We then throw away tags with text that is in all caps and surrounded by parentheses (e.g. '(APPLAUSEE)' and '(LAUGHTER)') because those don't correspond to any debaters' speech and therefore, don't add anything of value to our analysis. \n",
    "\n",
    "After that, we loop through the text of the remaining `<p>` tags to get the names of the person speaking, and the contents of what they said. In some cases, this is easy, we set up a regular expression to match strings like `\"BULLOCK: That's how I win. That's how we can take back the office.\"` and split them up into `'BULLOCK'` and `'That's how I win. That's how we can take back the office.'`. However, there are cases where a candidate's speech is broken up into multiple `<p>` tags, e.g.\n",
    "```html\n",
    "<p>WARREN: No. It is my way of talking about I know how to fight and I know how to win. I took on giant banks, and I beat them. I took on Wall Street, and CEOs, and their lobbyists, and their lawyers, and I beat them. I took on a popular Republican incumbent senator, and I beat him.</p>\n",
    "\n",
    "<p>I remember when people said Barack Obama couldn't get elected. Shoot, I remember when people said Donald Trump couldn't get elected. But here's where we are.</p>\n",
    "```\n",
    "\n",
    "In those cases, we need to keep track of the last name we saw, and if the regular expression doesn't pick up a name in the current `<p>`, assign that last name to the current text.\n",
    "\n",
    "Once we have the name of the current speaker, we can discard what the moderators say, and then count up the words that the candidates say."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "# scraped from https://en.wikipedia.org/wiki/Most_common_words_in_English\n",
    "common_words_list = [\"the\", \"be\", \"is\", \"was\", \"were\", \"are\", \"am\", \"to\", \"of\", \"and\", \"a\", \"an\", \"in\", \"that\", \"that's\", \"have\", \"has\", \"had\", \"i\", \"i'm\", \"i've\", \"it\", \"it's\", \"for\", \"not\", \"on\", \"with\", \"he\", \"as\", \"you\", \"you're\", \"do\", \"don't\", \"did\", \"at\", \"this\", \"but\", \"his\", \"by\", \"from\", \"they\", \"they've\", \"they're\", \"we\", \"we've\", \"we're\", \"say\", \"her\", \"she\", \"or\", \"will\", \"my\", \"one\", \"all\", \"would\", \"there\", \"there's\", \"their\", \"what\", \"so\", \"up\", \"out\", \"if\", \"about\", \"who\", \"get\", \"got\", \"which\", \"go\", \"me\", \"when\", \"make\", \"can\", \"can't\", \"like\", \"time\", \"no\", \"just\", \"him\", \"know\", \"take\", \"people\", \"into\", \"year\", \"your\", \"good\", \"some\", \"could\", \"them\", \"see\", \"other\", \"than\", \"then\", \"now\", \"look\", \"only\", \"come\", \"its\", \"over\", \"think\", \"also\", \"back\", \"after\", \"use\", \"two\", \"how\", \"our\", \"work\", \"first\", \"well\", \"way\", \"even\", \"new\", \"want\", \"because\", \"any\", \"these\", \"those\", \"give\", \"day\", \"most\", \"us\"]\n",
    "common_words = set(common_words_list)\n",
    "sorted_candidate_frequencies = {}\n",
    "\n",
    "for candidate, freqs in word_frequencies.items():\n",
    "    sorted_frequencies = sorted(freqs.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    sorted_candidate_frequencies[candidate] = []\n",
    "    for el in sorted_frequencies:\n",
    "        if el[0] not in common_words:\n",
    "            sorted_candidate_frequencies[candidate].append(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we are scraping the Wikipedia list of 100 most common English words using this JavaScript snippet:\n",
    "```javascript\n",
    "Array.from(document.querySelector('table').querySelectorAll('tbody td:first-child')).map((el) => el.innerText.toLowerCase())\n",
    "```\n",
    "\n",
    "I have also made some additions to the final list, such as conjugations (e.g. be, is, am, are, etc.), as well as some common contractions e.g. \"i'm\", \"it's\", etc. and tenses e.g. \"have\" vs \"had\". This will let us filter those common words out and get at the substance of what each candidate is talking about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell just defines a function for exploratory visualization later\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=['going', 'america', 'american',  'americans', 'need', 'president', 'too', 'put']\n",
    "def make_wordcloud(text, title):\n",
    "    wordcloud = WordCloud(background_color=\"white\",stopwords=stopwords , collocations=False).generate(text)\n",
    "    plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.suptitle(title, fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "candidate_strings = {}\n",
    "for k,v in sorted_candidate_frequencies.items():\n",
    "    words_as_string = ''\n",
    "    for word, freq in v:\n",
    "        for n in range(freq):\n",
    "            words_as_string = words_as_string + ' ' + word\n",
    "    candidate_strings[k] = words_as_string\n",
    "    make_wordcloud(words_as_string, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first exploratory data visualization, we are creating a word cloud for each candidate. The first set of word clouds I generated had some useless words which jumped out in most candidates' speech. Most notable among these were \"going\", which came up a lot in several candiates' speech, as well as \"america\" and \"american\" which were consitantly used by all candiates. Therefore, it has been added to the `stopwords` array, which contains words which should be ingnored.\n",
    "\n",
    "It was about here that I realized that 'health' and 'care' are showing up seperatly so often because the article sometimes writes \"healthcare\" and sometimes writes \"health care\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bar_chart(data, title):\n",
    "    # takes a list of tuples and turns it into a chart\n",
    "    # implementation taken from https://stackoverflow.com/questions/42612318/build-a-bar-chart-from-a-list-of-tuples-python?rq=1\n",
    "    plt.bar(range(len(data[:25])), [val[1] for val in data[:25]], align='center')\n",
    "    plt.xticks(range(len(data[:25])), [val[0] for val in data[:25]])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.suptitle(title, fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "for k,v in sorted_candidate_frequencies.items():\n",
    "    filtered_words = [a for a in v if a[0] not in stopwords]\n",
    "    make_bar_chart(filtered_words, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have charts of the 25 most common words from each of the candidates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
